# infer.py
import tenseal as ts
import torch
import torch.nn as nn
from torchvision import datasets
import torchvision.transforms as transforms
import numpy as np
import multiprocessing # Import multiprocessing
import time # To measure execution time
import os # To get CPU count

# Assuming ConvNet and data_generator are correctly imported from your files
from model import ConvNet
from datafucker import data_generator

class EncConvNet:
    """
    Encrypted Convolutional Neural Network using TenSEAL.
    Assumes the corresponding PyTorch model (ConvNet) has been trained
    and its weights are loaded.
    """
    def __init__(self, torch_nn=None, weights_dict=None):
        """
        Initialize EncConvNet. Can be initialized with a PyTorch model
        or a dictionary of weights (for loading in worker processes).
        """
        if torch_nn is not None:
            # Extract and format weights and biases from the trained PyTorch model
            # Conv1 weights: (out_channels, in_channels, kernel_h, kernel_w) -> (out_channels, kernel_h, kernel_w) for im2col
            self.conv1_weight = torch_nn.conv1.weight.data.view(
                torch_nn.conv1.out_channels, torch_nn.conv1.kernel_size[0],
                torch_nn.conv1.kernel_size[1]
            ).tolist()
            self.conv1_bias = torch_nn.conv1.bias.data.tolist()

            # FC1 weights: (out_features, in_features) -> Transpose for matrix multiplication (in_features, out_features)
            self.fc1_weight = torch_nn.fc1.weight.T.data.tolist()
            self.fc1_bias = torch_nn.fc1.bias.data.tolist()

            # FC2 weights: (out_features, in_features) -> Transpose for matrix multiplication (in_features, out_features)
            self.fc2_weight = torch_nn.fc2.weight.T.data.tolist()
            self.fc2_bias = torch_nn.fc2.bias.data.tolist()
        elif weights_dict is not None:
            # Load weights from a dictionary (used in worker processes)
            self.conv1_weight = weights_dict['conv1_weight']
            self.conv1_bias = weights_dict['conv1_bias']
            self.fc1_weight = weights_dict['fc1_weight']
            self.fc1_bias = weights_dict['fc1_bias']
            self.fc2_weight = weights_dict['fc2_weight']
            self.fc2_bias = weights_dict['fc2_bias']
        else:
            raise ValueError("Either torch_nn or weights_dict must be provided.")


    def forward(self, enc_x, windows_nb):
        """
        Forward pass through the encrypted network with timing.

        Args:
            enc_x (ts.CKKSVector): Encrypted input image data (after im2col).
            windows_nb (int): Number of windows generated by im2col.

        Returns:
            tuple: (ts.CKKSVector, dict) - Encrypted output (logits) and timing dictionary.
        """
        timing = {} # Dictionary to store timing for each layer

        # Conv layer 1
        start_time = time.time()
        enc_channels = []
        # Iterate through each kernel and its corresponding bias
        for kernel, bias in zip(self.conv1_weight, self.conv1_bias):
            # Perform encrypted 2D convolution using im2col
            y = enc_x.conv2d_im2col(kernel, windows_nb) + bias
            enc_channels.append(y)
        timing['conv1'] = time.time() - start_time

        # Pack all encrypted channels into a single flattened encrypted vector
        start_time = time.time()
        enc_x = ts.CKKSVector.pack_vectors(enc_channels)
        timing['pack'] = time.time() - start_time

        # Square activation (approximation of ReLU in HE)
        start_time = time.time()
        enc_x.square_()
        timing['square1'] = time.time() - start_time

        # Fully Connected Layer 1
        start_time = time.time()
        enc_x = enc_x.mm(self.fc1_weight) + self.fc1_bias
        timing['fc1'] = time.time() - start_time

        # Square activation
        start_time = time.time()
        enc_x.square_()
        timing['square2'] = time.time() - start_time

        # Fully Connected Layer 2 (Output layer)
        start_time = time.time()
        enc_x = enc_x.mm(self.fc2_weight) + self.fc2_bias
        timing['fc2'] = time.time() - start_time

        return enc_x, timing # Return timing dictionary


    def __call__(self, *args, **kwargs):
        return self.forward(*args, **kwargs)

    def get_weights_dict(self):
        """Returns weights and biases as a dictionary for serialization."""
        return {
            'conv1_weight': self.conv1_weight,
            'conv1_bias': self.conv1_bias,
            'fc1_weight': self.fc1_weight,
            'fc1_bias': self.fc1_bias,
            'fc2_weight': self.fc2_weight,
            'fc2_bias': self.fc2_bias,
        }


# Corrected function signature to accept a single context_bytes object
def process_single_sample(image_data_list, target_label, context_bytes, model_weights_dict, kernel_shape, stride):
    """
    Worker function to process a single sample for encrypted inference.
    Runs in a separate process.

    Args:
        image_data_list (list): Flattened list of image pixel data.
        target_label (int): The true label for the image.
        context_bytes (bytes): Serialized TenSEAL context (including secret key).
        model_weights_dict (dict): Dictionary of model weights and biases.
        kernel_shape (tuple): Shape of the convolutional kernel (height, width).
        stride (int): Stride of the convolution.

    Returns:
        tuple: (loss_item, predicted_label, true_label, timing_dict) - loss, prediction, true label, and timing.
    """
    # Deserialize context - it now contains the secret key
    context = ts.context_from(context_bytes) # Use context_from to deserialize

    enc_model = EncConvNet(weights_dict=model_weights_dict)

    # Create a simple criterion for loss calculation (plaintext)
    criterion = nn.CrossEntropyLoss()

    timing_dict = {} # Dictionary to store timing for this sample

    try:
        # Encoding and encryption for the single image
        start_time = time.time()
        x_enc, windows_nb = ts.im2col_encoding(
            context,
            image_data_list,
            kernel_shape[0],
            kernel_shape[1],
            stride
        )
        timing_dict['encode_encrypt'] = time.time() - start_time

        # Encrypted evaluation (calls EncConvNet.forward which now returns layer timings)
        start_time = time.time() # Time the overall forward pass excluding encode/decrypt
        enc_output, layer_timing = enc_model(x_enc, windows_nb) # Get layer timings from forward
        timing_dict.update(layer_timing) # Add layer timings to the sample's timing dict
        timing_dict['encrypted_forward_total'] = time.time() - start_time # Total time for encrypted forward

        # Decryption of result
        start_time = time.time()
        output = enc_output.decrypt()
        timing_dict['decrypt'] = time.time() - start_time

        # Convert decrypted list back to a torch tensor, shape (1, num_classes)
        output = torch.tensor(output).view(1, -1)

        # Convert target label to torch tensor (shape 1) for loss calculation
        single_target_tensor = torch.tensor([target_label]).view(1)


        # compute loss (using plaintext output and target)
        loss = criterion(output, single_target_tensor)
        loss_item = loss.item()

        # convert output probabilities to predicted class
        _, pred = torch.max(output, 1)
        predicted_label = pred.item()
        true_label = target_label # target_label is already the scalar true label

        return (loss_item, predicted_label, true_label, timing_dict) # Return timing dict


    except Exception as e:
        print(f"Error processing a sample in worker: {e}")
        # Return None or a specific error indicator if processing fails
        return None


def enc_test_parallel(context, enc_model, test_loader, criterion, kernel_shape, stride, max_samples=None, num_processes=None):
    """
    Evaluates the encrypted model on a subset or the entire test set using multiprocessing.

    Args:
        context (ts.Context): TenSEAL context (should contain all keys including secret key).
        enc_model (EncConvNet): The encrypted model.
        test_loader (DataLoader): DataLoader for the test set.
        criterion (torch.nn.Module): Loss function (used here for calculating plaintext loss).
        kernel_shape (tuple): Shape of the convolutional kernel (height, width).
        stride (int): Stride of the convolution.
        max_samples (int, optional): Maximum number of samples to process.
                                     If None, process the entire test set.
        num_processes (int, optional): Number of worker processes to use.
                                       If None, uses the number of CPU cores.
    """
    print("Starting encrypted evaluation with multiprocessing...")
    if max_samples is not None:
        print(f"Processing a maximum of {max_samples} samples.")

    # --- Prepare data and arguments for parallel processing ---
    all_samples_data = []
    print("Collecting test data...")
    for data, target in test_loader:
        for i in range(data.size(0)):
            if max_samples is not None and len(all_samples_data) >= max_samples:
                break # Stop collecting if max_samples is reached
            # Reshape the single image to (height, width) and convert to list
            image_data_list = data[i].view(28, 28).tolist()
            target_label = target[i].item()
            all_samples_data.append((image_data_list, target_label))
        if max_samples is not None and len(all_samples_data) >= max_samples:
            break # Stop collecting if max_samples is reached

    print(f"Collected {len(all_samples_data)} samples for parallel processing.")

    if len(all_samples_data) == 0:
        print("No samples to process.")
        return

    # Serialize the context including the secret key
    print("Serializing context (including secret key)...")
    context_bytes = context.serialize(
        save_public_key=True,
        save_secret_key=True, # Explicitly save secret key here
        save_relin_keys=True,
        save_galois_keys=True
    )
    model_weights_dict = enc_model.get_weights_dict()
    print("Serialization complete.")

    # Prepare arguments list for starmap
    task_arguments = [
        (img_list, label, context_bytes, model_weights_dict, kernel_shape, stride)
        for img_list, label in all_samples_data
    ]

    # --- Parallel Processing ---
    if num_processes is None:
        num_processes = os.cpu_count() # Use all available CPU cores
    print(f"Using {num_processes} worker processes.")

    start_time_total = time.time() # Start total timing
    results = []
    with multiprocessing.Pool(processes=num_processes) as pool:
        results = pool.starmap(process_single_sample, task_arguments)

    end_time_total = time.time() # End total timing
    print(f"Total parallel processing time: {end_time_total - start_time_total:.2f} seconds.")


    # --- Aggregate Results ---
    test_loss = 0.0
    class_correct = list(0. for i in range(10))
    class_total = list(0. for i in range(10))
    processed_count = 0

    # Dictionary to sum up timings across all samples
    aggregated_timing = {
        'encode_encrypt': 0.0,
        'conv1': 0.0,
        'pack': 0.0,
        'square1': 0.0,
        'fc1': 0.0,
        'square2': 0.0,
        'fc2': 0.0,
        'encrypted_forward_total': 0.0,
        'decrypt': 0.0,
    }

    print("Aggregating results...")
    for result in results:
        if result is not None: # Check if sample processing was successful
            loss_item, predicted_label, true_label, timing_dict = result # Unpack timing_dict
            test_loss += loss_item
            class_correct[true_label] += (predicted_label == true_label)
            class_total[true_label] += 1
            processed_count += 1

            # Sum up timings
            for key, value in timing_dict.items():
                 if key in aggregated_timing: # Ensure key exists in aggregation dict
                    aggregated_timing[key] += value

    if processed_count == 0:
        print("No samples were successfully processed.")
        return

    # calculate and print avg test loss
    test_loss = test_loss / processed_count
    print(f'Test Loss: {test_loss:.6f}\n')

    # Print accuracy per class
    for label in range(10):
        if class_total[label] > 0:
            print(
                f'Test Accuracy of {label}: {int(100 * class_correct[label] / class_total[label])}% '
                f'({int(class_correct[label])}/{int(class_total[label])})'
            )
        else:
             print(f'Test Accuracy of {label}: N/A (no samples for this class)')

    # Print overall accuracy
    print(
        f'\nTest Accuracy (Overall): {int(100 * np.sum(class_correct) / processed_count)}% '
        f'({int(np.sum(class_correct))}/{int(processed_count)})'
    )

    # --- Print Average Layer Timings ---
    print("\nAverage Layer Processing Times (per sample):")
    for layer_name, total_time in aggregated_timing.items():
        if processed_count > 0:
            average_time = total_time / processed_count
            print(f"  {layer_name}: {average_time:.6f} seconds")
        else:
            print(f"  {layer_name}: N/A (no samples processed)")


# --- Main execution block ---

# Add this guard for multiprocessing on some systems (especially Windows)
if __name__ == '__main__':
    # Load one element at a time (or batches, but processing is sample-by-sample for encryption)
    train_loader, test_loader = data_generator() # Assuming this returns PyTorch DataLoaders

    # required for encoding (get kernel shape and stride from a dummy model instance)
    try:
        # Load the trained PyTorch model state_dict
        trained_model = ConvNet()
        # IMPORTANT: Load your trained model weights here
        # Replace 'path/to/your/trained_model.pth' with the actual path
        trained_model.load_state_dict(torch.load('plainmodel.pt'))
        trained_model.eval() # Set to evaluation mode

        # Get kernel shape and stride from the loaded model's conv layer
        kernel_shape = trained_model.conv1.kernel_size
        stride = trained_model.conv1.stride[0]

        print("Loaded trained PyTorch model.")

    except FileNotFoundError:
        print("Error: Trained model file not found.")
        print("Please ensure 'path/to/your/trained_model.pth' points to your trained model weights.")
        exit()
    except Exception as e:
        print(f"An error occurred while loading the trained model: {e}")
        exit()


    ## Encryption Parameters

    # controls precision of the fractional part
    bits_scale = 26

    # Create TenSEAL context
    # Generate secret key, relinearization keys, and galois keys in the main process
    context = ts.context(
        ts.SCHEME_TYPE.CKKS,
        poly_modulus_degree=8192,
        coeff_mod_bit_sizes=[31, bits_scale, bits_scale, bits_scale, bits_scale, bits_scale, bits_scale, 31]
    )

    # set the scale
    context.global_scale = pow(2, bits_scale)

    # Generate relinearization keys (needed for encrypted multiplication)
    context.generate_relin_keys() # Generate relin keys
    # Generate galois keys (needed for rotations, used in im2col and packing)
    context.generate_galois_keys() # Generate galois keys
    # The secret key is automatically generated when relin/galois keys are generated
    # or can be accessed via context.secret_key() after context creation.

    # Initialize the encrypted model with weights from the trained PyTorch model
    enc_model = EncConvNet(torch_nn=trained_model)

    # Define the criterion (for plaintext loss calculation during evaluation)
    criterion = nn.CrossEntropyLoss()

    # Run the encrypted test with multiprocessing
    # Serialize and pass the context including the secret key
    enc_test_parallel(
        context, # Pass the context which now holds all keys
        enc_model,
        test_loader,
        criterion,
        kernel_shape,
        stride,
        max_samples=1000, # Example: process 100 samples
        num_processes=os.cpu_count() # Example: use all available CPU cores
        # num_processes=12 # Or specify a fixed number, e.g., 12 for your vCPUs
    )

